\section{Relation Vectors (Ben)}

	One of the ways that one could tell that the answer to \textit{Which example describes a learned behavior in a dog?} is \textit{Sitting on command} is that the relationship between \textit{dog} and \textit{command} is similar the meaning of the word \textit{learn}. Importantly, the meaning is not \emph{exactly} the same as \textit{learn}, only similar. In order to attempt to capture this kind of fact, three kinds of embeddings were learned. An embedding matrix $V$ for two-place predicates was learned, such that, for example, $\mathbf{v}_{learn}$ would be a vector in a 200-dimensional real vector space. Embedding matrices $S$ and $O$, for arguments to two-place predicates, were also learned, so $\mathbf{s}_{dog}$ and $\mathbf{o}_{command}$ were also vectors in 200-dimensional real vector spaces. Finally, a $200\times 400$ weight matrix $W$ was also learned, such that if the relationship between $i$ and $j$ is approximately the same as the meaning of $k$, then $tanh(W \langle \mathbf{s}_{i} , \mathbf{o}_{j} \rangle) \approx \mathbf{v}_{k}$. 
    
    This was all implemented as a Neural Network, using Lasagne\footnote{\url{github.com/Lasagne/Lasagne}}, which is built on Theano[\ref{THEANO2,THEANO1}]. Data was taken from Simple English Wikipedia, parsed using Processors[\ref{processors}]. After excluding a manually-defined list of dependency types, roots which took exactly two arguments were selected, and used to train the network using a Mean Squared Error cost function and Nesterov momentum.
    
   	The results were not good. While the training generalized to a held-out validation data set consisting of $\%10$ of the Simple Wiki data, this did not translate to sensible embeddings. For example, the cosine similarity between the vector predicted for the noun pair \textit{dog}+\textit{command} and the embedding learned for \textit{learn} was $-.09$, meaning that they were essentially unrelated, and even slightly pointed in opposite directions. Using these vectors to answer questions for the challenge was no better than chance ($\%25.8$), so these vectors were not included in the overall Ensemble model.